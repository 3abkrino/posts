---
message: |-
  I'm getting (Additionally, a 500 Internal Server Error error was encountered while trying to use an ErrorDocument to handle the request) after about 10 minutes from running my php file, The page has a lot of CURL Requests in it, I have all timeouts and max execution time set to 0 :

  @ini_set('max_execution_time', '0');
  @ini_set('max_input_time', '0');
  @ini_set('mbstring.func_overload', '0');
  @ini_set('output_handler', '');
  @ini_set('default_socket_timeout','10');
  @ini_set('memory_limit','512M');
  @set_time_limit(0);

  And still getting the same error.

  * This problem only happened when number of CURL Requests raised means it was working till yesterday and I'm pretty sure the code has nothing wrong with it.

  any Ideas ?
from:
  name: Mostafa Kasem
  id: '2342288709130763'
type: status
created_time: '2015-09-22T22:22:22+0000'
updated_time: '2015-09-23T07:04:30+0000'
permalink_url: https://www.facebook.com/groups/egyptian.geeks/permalink/1010490118990696/
id: '172338516139198_1010490118990696'
reactions:
  data:
  - id: '1558338227577130'
    name: Ahmed Ali
    type: LIKE
  paging:
    cursors:
      before: TVRBd01EQXlNREk1TURNME1UQXhPakUwTkRJNU5qQTVORFk2TWpVME1EazJNVFl4TXc9PQZDZD
      after: TVRBd01EQXlNREk1TURNME1UQXhPakUwTkRJNU5qQTVORFk2TWpVME1EazJNVFl4TXc9PQZDZD
comments:
  data:
  - created_time: '2015-09-22T22:26:29+0000'
    from:
      name: Morad Edwar
      id: '10215772499725897'
    message: what about running the cURLs in parallel?? search and I think there is
      a way to do that in PHP.
    id: '1010490828990625'
  - created_time: '2015-09-22T22:28:14+0000'
    from:
      name: Sherif Omar
      id: '10159954581715092'
    message: The timeout can also be at the apache level. Running a PHP script for
      more than 10 minutes is very poor design. Break it up into tasks and cron it
    id: '1010491205657254'
  - created_time: '2015-09-22T22:29:20+0000'
    from:
      name: Ahmed Al-Amir
      id: '10156207737619180'
    message: Check the logs. Google the error there. Post on StackOverflow.
    id: '1010491392323902'
  - created_time: '2015-09-22T22:33:09+0000'
    from:
      name: Morad Edwar
      id: '10215772499725897'
    message: Also you can split the requests to steps and make ajax request to execute
      the first step hen the next one in the callback of the ajax request and go on
      and tell the user about the progress depending on the total requests - the finished
      .. that's just in case you will use it as a web page not a service file
    id: '1010492215657153'
  - created_time: '2015-09-23T07:04:30+0000'
    from:
      name: Mohamed Hassan Hammam
      id: '2090162694546503'
    message: "first , there is fatal error will appear to you && Maximum execution
      time  will be exceeded >>>\nthe problem in max_execution_time ---> to fetch
      the data \n -->solution\n ini_set('max_execution_time',240); the time in second
      \n-----\nif there is  https in the urls , write:\n$opts = array('http'=>array('header'
      => \"User-Agent:MyAgent/1.0\\r\\n\"));\n$context = stream_context_create($opts);\n$html
      = file_get_contents(\"https://www.***.com/**\",false,$context);"
    id: '1010628352310206'
  paging:
    cursors:
      before: WTI5dGJXVnVkRjlqZAFhKemIzSTZANVEF4TURRNU1EZA3lPRGs1TURZAeU5Ub3hORFF5T1RZAd056a3cZD
      after: WTI5dGJXVnVkRjlqZAFhKemIzSTZANVEF4TURZAeU9ETTFNak14TURJd05qb3hORFF5T1RreE9EY3cZD
